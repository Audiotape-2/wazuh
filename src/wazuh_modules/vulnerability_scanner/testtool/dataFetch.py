import sys
import requests
from bs4 import BeautifulSoup

# Get argument and store it in variable
out_folder = sys.argv[1]

# URL of the website to scrape
url = "https://rpmfind.net/linux/RPM/ByName.html"

# Base URL of the website
url_base = "https://rpmfind.net/linux/RPM/"

# Send a GET request to the URL
response = requests.get(url)

# Check if the request was successful
if response.status_code == 200:
    print("Data retrieved successfully")
    # Parse the HTML content of the response
    soup = BeautifulSoup(response.content, "html.parser")

    # Find all the internal links in the HTML
    links = soup.find_all("a")

    # Flag to break the loop and avoid re-visiting links
    stop = False

    # Follow each internal link and print the values
    for link in links:
        print(f"Link: {link.get('href')}")
        href = link.get("href")
        if not href.startswith("/"):
            if href.startswith("A") and not stop:
                stop = True
            elif href.startswith("A") and stop:
                break
            internal_url = url_base + href
            internal_response = requests.get(internal_url)
            if internal_response.status_code == 200:
                print(f"Data retrieved successfully from {internal_url}")
                internal_soup = BeautifulSoup(internal_response.content, "html.parser")
                packages = internal_soup.find_all("tr")
                skip_first = True
                # Create a file to store the results
                with open(f"{out_folder}/{href}.out", "w") as file:
                    # Create a dictionary of arrays to store the results
                    dict = {}
                    for package in packages:
                        if skip_first:
                            skip_first = False
                            continue
                        td_list = package.find_all("td")
                        if td_list:
                            name_version = td_list[0].get_text()
                            # Equivalent to "rev | cut -d- -f3- | rev"
                            name = name_version[::-1].split("-", 2)[-1][::-1]
                            version = name_version[len(name)+1:]
                            if name in dict:
                                dict[name].append(version)
                            else:
                                dict[name] = [version]

                    for name, version in dict.items():
                        file.write(f"{name}")
                        for v in version:
                            file.write(f" {v}")
                        file.write("\n")

            else:
                print(f"Failed to retrieve data from {internal_url}")
else:
    print("Failed to retrieve data from the website")
